### <p align="center" > TECNOLÓGICO NACIONAL DE MÉXICO</p>

### <p align="center" > INSTITUTO TECNOLÓGICO DE TIJUANA</p>

### <p align="center" > SUBDIRECCIÓN ACADÉMICA </p>

### <p align="center" > DEPARTAMENTO DE SISTEMAS Y COMPUTACIÓN </p>

### <p align="center" > PERIODO: Febrero-Julio  2021</p>


###  <p align="center">  Carrera: Ing. En Sistemas Computacionales. 
### <p align="center"> Materia: 	Datos Masivos (BDD-1704 SC9A	).</p>

### <p align="center">  Maestro: Jose Christian Romero Hernandez	</p>
### <p align="center">  No. de control y nombre del alumno: 16210273 - Calderon Acuna Jose Eduardo </p>
### <p align="center">  No. de control y nombre del alumno: 15210743 - Vasquez Macias Cristo Josue</p>


## Index


* [Introducction](#intro)
* [Theoretical Framework](#Th)
    * [Support Vector Machine](#SVM)
    * [Decision Tree Classifier](#Decision-tree)
    * [Logistic Regression](#LR)
    * [Multilayer Perceptron](#MP)
* [Implementation](#Implementation)
* [Results](#Results)
* [Conclusions](#Conclisions)
* [References](#References)

<div id='intro'/>

# Introduction 

Big Data is a broad term for very large or complex data sets that traditional data processing applications are not insufficient to handle. The challenges this new technology presents include analysis, capture, preservation, search, sharing, storage, transfer, display, and privacy information.
In this project we will work with different machine learning algorithms that will help us to better handle the data that we will classify.

<div id='Th'/>

# Theoretical framework

<div id='SVM'/>

## Support Vector Machine

Support Vector Machines constitute a learning-based method for solving classification and regression problems. In both cases, this resolution is based on a first training phase (where they are informed with multiple examples already solved, in the form of pairs {problem, solution}) and a second phase of use for problem solving. In it, SVMs become a "black box" that provides an answer (output) to a given problem (input).

![SVM](https://www.merkleinc.com/es/sites/es/files/inline-images/ml_1.png)

## Decision Tree Classifier

A decision tree or classification tree is a tree in which each internal node (not leaf) is labeled with an input function. The arcs from a node labeled with a feature are labeled with each of the possible values of the feature.

#### Utilization
Decision trees are used in any process that involves decision making, some of these examples are:

* Binary search
* Game trees
* Product planning
* Process analysis
* Plant capacity

#### Advantage
* Some of the advantages of this algorithm are the following:
* Decision trees are easy to interpret and visualize.
* You can easily capture non-linear patterns.
* It requires less data preprocessing by the user, for example, no need to normalize columns.
* It can be used for feature engineering, such as missing value prediction, suitable for variable selection.
* The decision tree has no assumptions about the distribution due to the nonparametric nature of the algorithm.

#### Disadvantages
For its part, the disadvantages of this algorithm are:

* Noise sensitive data, you can oversize noisy data.
* The small variation in the data can lead to a different decision tree.
* They are biased with an unbalanced dataset, so it is recommended to balance the dataset before creating the decision tree.

## Implementation

For the demonstration of the methods of analysis and verification of problems towards the data generated in a result that is verified in bigdata, the task was carried out to find an implementation tool for the use of data manipulation for as well as to generate viable results and effective, for what I entail in this course in using Spark, first of all we will explain that Spark is, as shown in different media and data science forums in Big Data and Machine Learning, it is a fast and efficient engine for storage and processing of the data in large volumes, which shows open source, this is the tool that provides agility in detecting patterns in the data, the organized classification of the information, the execution of intensive computation on the data and parallel processing clusters.

For us it is understandable since its advantages are something good such as:

* Simplify the smart solution development process.
* Improve the performance of data-dependent applications.
* Unify the algorithms so that they work together on various tasks.
* Integrate analytical data modeling within itself.
* Grant scalability in its power by introducing more processors in the system.
* Reduces costs by being able to use standard hardware in common use.

## Results


## Conclusions

## References

## 





